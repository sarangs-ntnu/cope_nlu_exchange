{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%bash\n",
        "pip install -q pandas scikit-learn numpy matplotlib seaborn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Augmentation\n",
        "Apply simple token dropout augmentation to expand the training data and evaluate impact.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(Path('../../data/comments.csv'))\n",
        "df['stratify_key'] = df['aspect'] + '_' + df['label']\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['stratify_key'])\n",
        "for frame in (train_df, test_df):\n",
        "    frame['text_with_aspect'] = 'Aspect: ' + frame['aspect'] + ' | ' + frame['comment']\n",
        "print(train_df.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "def token_dropout(text, drop_prob=0.1):\n",
        "    tokens = text.split()\n",
        "    kept = [t for t in tokens if random.random() > drop_prob]\n",
        "    return ' '.join(kept) if kept else text\n",
        "\n",
        "augmented = train_df.copy()\n",
        "augmented['text_with_aspect'] = augmented['text_with_aspect'].apply(lambda t: token_dropout(t, 0.2))\n",
        "combined = pd.concat([train_df, augmented], ignore_index=True)\n",
        "print(f\"Original train size: {len(train_df)}, after augmentation: {len(combined)}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    baseline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
        "        ('clf', LogisticRegression(max_iter=400))\n",
        "    ])\n",
        "    baseline.fit(train_df['text_with_aspect'], train_df['label'])\n",
        "    base_preds = baseline.predict(test_df['text_with_aspect'])\n",
        "    print('Baseline (no augmentation)')\n",
        "    print(classification_report(test_df['label'], base_preds))\n",
        "\n",
        "    aug_model = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
        "        ('clf', LogisticRegression(max_iter=400))\n",
        "    ])\n",
        "    aug_model.fit(combined['text_with_aspect'], combined['label'])\n",
        "    aug_preds = aug_model.predict(test_df['text_with_aspect'])\n",
        "    print('\n",
        "With augmentation')\n",
        "    print(classification_report(test_df['label'], aug_preds))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}